{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, EsmForSequenceClassification\n",
    "import torch\n",
    "import pandas as pd\n",
    "import esm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PF01250.17', 'PF02261.16', 'PF03015.19', 'PF06094.12'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set(pd.read_csv(\"../transformer/pfam_tiny_1579.train.csv\")['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_mem_info_reset():\n",
    "    device = 'cuda:0'\n",
    "    alloc = torch.cuda.memory_allocated(device) / (1024*1024)\n",
    "    res = torch.cuda.memory_reserved(device) / (1024*1024)\n",
    "    max_alloc = torch.cuda.max_memory_allocated(device) / (1024*1024)\n",
    "    max_res = torch.cuda.max_memory_reserved(device) / (1024*1024)\n",
    "    # torch.cuda.empty_cache()\n",
    "    # torch.cuda.reset_peak_memory_stats()\n",
    "    print(f\"Allocated: {alloc} Reserved: {res} Max_alloc: {max_alloc} Max_res: {max_res}\")\n",
    "\n",
    "\n",
    "def count_model_size_mb(model):\n",
    "    return sum(p.nelement() * p.element_size() for p in model.parameters()) / (1024 * 1024)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.nelement() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 142.88037109375 Reserved: 6282.0 Max_alloc: 142.88037109375 Max_res: 6282.0\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch_mem_info_reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be used\n",
    "# model, alphabet = torch.hub.load(\"facebookresearch/esm:main\", \"esm2_t6_8M_UR50D\")\n",
    "# model, alphabet = esm.pretrained.esm2_t12_35M_UR50D()\n",
    "model, alphabet = esm.pretrained.esm2_t30_150M_UR50D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33, 640])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_model_size_mb(model)\n",
    "next(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<class 'torch.nn.modules.module.Module'>,)\n"
     ]
    }
   ],
   "source": [
    "# model has a base class nn.Module\n",
    "print(esm.model.esm2.ESM2.__bases__)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Identity\n",
    "model.contact_head = Identity()\n",
    "model.emb_layer_norm_after = Identity()\n",
    "model.lm_head = Identity()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>corrupted</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M L R M M M N S K I H R A T V T E A D L N Y V ...</td>\n",
       "      <td>M L R M M M N S K I H R A T V T E A D L N Y V ...</td>\n",
       "      <td>PF02261.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L F V Y G T L R Q G E S N H N F L A D S Q C L ...</td>\n",
       "      <td>L F V Y G T L R Q G E S N H N F L A D S Q C L ...</td>\n",
       "      <td>PF06094.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P Y E L M V L L R P D L A D D R L E A A L E R ...</td>\n",
       "      <td>P Y E L M V L L R P D L X D D R L V A A L E R ...</td>\n",
       "      <td>PF01250.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y E L F A L A K P Q L G K K A I A S I M K A V ...</td>\n",
       "      <td>Y E L F A L A K P V L G T K A I A S I M K A V ...</td>\n",
       "      <td>PF01250.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q I K L M H A K L H H L R V T Q A E L D Y V G ...</td>\n",
       "      <td>Q I K L M H A K L H H L R V T Q A E L D Y V G ...</td>\n",
       "      <td>PF02261.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>F Q K L P A Y I I D F G A W I T G R K P M Q V ...</td>\n",
       "      <td>F Q K V P A Y I I D F G A W I T G E K P M Q V ...</td>\n",
       "      <td>PF03015.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>L Y E T M Y I I R P D L G E E T V D Q V I N Q ...</td>\n",
       "      <td>L Y E T M Y I I R P D L G E E T V D Q V I N Q ...</td>\n",
       "      <td>PF01250.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>K Y E V M Y I V K P T L D E E A R T A V I A K ...</td>\n",
       "      <td>K Y N V M Y I V K P T L D E E A R T A V I A K ...</td>\n",
       "      <td>PF01250.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>A Y E I L Y I I R P D M D E E A T N A L V D R ...</td>\n",
       "      <td>A Y E I L Y I I R P D M D E E A T N A L V D R ...</td>\n",
       "      <td>PF01250.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>L D Y V P A L V A D L L A V L H G N A P D S W ...</td>\n",
       "      <td>L D Y V P A L V A D L L A V L H G N A P D S W ...</td>\n",
       "      <td>PF03015.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1579 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               original  \\\n",
       "0     M L R M M M N S K I H R A T V T E A D L N Y V ...   \n",
       "1     L F V Y G T L R Q G E S N H N F L A D S Q C L ...   \n",
       "2     P Y E L M V L L R P D L A D D R L E A A L E R ...   \n",
       "3     Y E L F A L A K P Q L G K K A I A S I M K A V ...   \n",
       "4     Q I K L M H A K L H H L R V T Q A E L D Y V G ...   \n",
       "...                                                 ...   \n",
       "1574  F Q K L P A Y I I D F G A W I T G R K P M Q V ...   \n",
       "1575  L Y E T M Y I I R P D L G E E T V D Q V I N Q ...   \n",
       "1576  K Y E V M Y I V K P T L D E E A R T A V I A K ...   \n",
       "1577  A Y E I L Y I I R P D M D E E A T N A L V D R ...   \n",
       "1578  L D Y V P A L V A D L L A V L H G N A P D S W ...   \n",
       "\n",
       "                                              corrupted       label  \n",
       "0     M L R M M M N S K I H R A T V T E A D L N Y V ...  PF02261.16  \n",
       "1     L F V Y G T L R Q G E S N H N F L A D S Q C L ...  PF06094.12  \n",
       "2     P Y E L M V L L R P D L X D D R L V A A L E R ...  PF01250.17  \n",
       "3     Y E L F A L A K P V L G T K A I A S I M K A V ...  PF01250.17  \n",
       "4     Q I K L M H A K L H H L R V T Q A E L D Y V G ...  PF02261.16  \n",
       "...                                                 ...         ...  \n",
       "1574  F Q K V P A Y I I D F G A W I T G E K P M Q V ...  PF03015.19  \n",
       "1575  L Y E T M Y I I R P D L G E E T V D Q V I N Q ...  PF01250.17  \n",
       "1576  K Y N V M Y I V K P T L D E E A R T A V I A K ...  PF01250.17  \n",
       "1577  A Y E I L Y I I R P D M D E E A T N A L V D R ...  PF01250.17  \n",
       "1578  L D Y V P A L V A D L L A V L H G N A P D S W ...  PF03015.19  \n",
       "\n",
       "[1579 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../transformer/pfam_tiny_1579.train.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_test = df['original'][2] * 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3700"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seq_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(seq_test)*100*480*4 / (1024*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free / (1024*1024)\n",
    "def check_gpu_mem(device):\n",
    "    free, total = torch.cuda.mem_get_info(device)\n",
    "    print(f\"Free: {free / (1024*1024)} Total: {total / (1024*1024)}\")\n",
    "\n",
    "def get_tensor_size_mb(tens):\n",
    "    sz = tens.element_size() * tens.nelement()\n",
    "    sz /= (1024 * 1024)\n",
    "    print(f\"Size MiB: {sz}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_converter = alphabet.get_batch_converter()\n",
    "data = [\n",
    "    # (\"protein1\", seq_test),\n",
    "    (\"protein2\", seq_test) for _ in range(20)\n",
    "    # (\"prot1\", \"ADPALVLH\"),\n",
    "    # (\"prot2\", \"ADPAL\"),\n",
    "    # (\"prot3\", \"AD\")\n",
    "]\n",
    "batch_labels, batch_strs, batch_tokens = batch_converter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "# alphabet.tok_to_idx\n",
    "# '<cls>': 0,\n",
    "#  '<pad>': 1,\n",
    "#  '<eos>': 2,\n",
    "#  '<unk>': 3,\n",
    "# ...\n",
    "# '.': 29,\n",
    "#  '-': 30,\n",
    "#  '<null_1>': 31,\n",
    "#  '<mask>': 32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "torch.int64\n",
      "Free: 21211.0 Total: 22515.75\n",
      "Size MiB: 0.142059326171875\n",
      "Size MiB: 0.142059326171875\n",
      "Size MiB: 0.017757415771484375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.uint8"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.cuda.is_available()\n",
    "print(batch_tokens.device)\n",
    "# torch.cuda.device_count()\n",
    "print(batch_tokens[0].dtype)\n",
    "check_gpu_mem(device)\n",
    "batch_tokens_gpu64 = batch_tokens.to(device)\n",
    "batch_tokens_gpu8 = batch_tokens.to(device).to(dtype=torch.uint8)\n",
    "# batch_tokens = batch_tokens.to(torch.int16)\n",
    "get_tensor_size_mb(batch_tokens)\n",
    "get_tensor_size_mb(batch_tokens_gpu64)\n",
    "get_tensor_size_mb(batch_tokens_gpu8)\n",
    "batch_tokens_gpu8.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free: 21211.0 Total: 22515.75\n",
      "Size MiB: 0.142059326171875\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# check_gpu_mem(device)\n",
    "# get_tensor_size_mb(batch_tokens)\n",
    "# batch_tokens.shape\n",
    "check_gpu_mem(device)\n",
    "get_tensor_size_mb(batch_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tot = torch.cuda.memory_reserved(device)\n",
    "# free, total = torch.cuda.mem_get_info(device)\n",
    "# tot / (1024*1024)\n",
    "batch_tokens.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc \n",
    "del batch_tokens\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters:  33501394\n",
      "Model size [MB]:  127.79767608642578\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of parameters: \", count_parameters(model))\n",
    "print(\"Model size [MB]: \", count_model_size_mb(model))\n",
    "# para = next(model.parameters())\n",
    "# para.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0525, -0.2617, -0.0292,  ..., -0.0635, -0.0179,  0.0432],\n",
       "        [-0.1777, -0.5977,  0.1943,  ...,  0.3672,  0.1357,  0.0131],\n",
       "        [ 0.0981, -0.2754,  0.0186,  ..., -0.0469,  0.1670, -0.0327],\n",
       "        ...,\n",
       "        [ 0.0022, -0.0425,  0.0080,  ...,  0.0479, -0.0464, -0.0066],\n",
       "        [-0.0014, -0.0260,  0.0347,  ...,  0.0342, -0.0659, -0.0422],\n",
       "        [-0.1807, -0.5977,  0.1934,  ...,  0.3711,  0.1455,  0.0138]],\n",
       "       dtype=torch.bfloat16, requires_grad=True)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next(model.parameters()).dtype\n",
    "# 35*1e6*4/(1024*1024*1024)\n",
    "model.to(torch.bfloat16)\n",
    "next(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33501394"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(next(model.parameters()).is_cuda)\n",
    "# model.cuda()\n",
    "print(next(model.parameters()).is_cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free: 22061.0 Total: 22515.75\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "check_gpu_mem(device)\n",
    "print(next(model.parameters()).is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 14, 19,  ...,  7, 10,  2],\n",
       "        [ 0, 14, 19,  ...,  7, 10,  2],\n",
       "        [ 0, 14, 19,  ...,  7, 10,  2],\n",
       "        ...,\n",
       "        [ 0, 14, 19,  ...,  7, 10,  2],\n",
       "        [ 0, 14, 19,  ...,  7, 10,  2],\n",
       "        [ 0, 14, 19,  ...,  7, 10,  2]], device='cuda:0', dtype=torch.uint8)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_tokens_gpu8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    res = model(batch_tokens_gpu64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikola_dev/miniconda3/envs/ssi/lib/python3.10/site-packages/torch/cuda/memory.py:329: FutureWarning: torch.cuda.reset_max_memory_cached now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n",
      "/home/nikola_dev/miniconda3/envs/ssi/lib/python3.10/site-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.reset_max_memory_cached()\n",
    "torch.cuda.reset_max_memory_allocated()\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 142.87841796875 Reserved: 6282.0 Max_alloc: 142.87841796875 Max_res: 6282.0\n"
     ]
    }
   ],
   "source": [
    "torch_mem_info_reset()\n",
    "# check_gpu_mem(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size MiB: 0.23439788818359375\n"
     ]
    }
   ],
   "source": [
    "get_tensor_size_mb(res['logits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logits': tensor([[[ 2.5057,  6.8665,  1.0299,  ...,  8.5440, -1.4410, -7.0620],\n",
       "          [ 4.4105,  2.9949, -1.7162,  ...,  4.4722, -0.3008, -2.9338],\n",
       "          [-0.7679, -2.4428, -1.0123,  ..., -1.6110,  2.6296,  0.2919],\n",
       "          ...,\n",
       "          [-1.7249, -1.8000,  4.2837,  ...,  1.0689, -0.8234, -5.0085],\n",
       "          [-0.1915, -0.7245,  2.4475,  ..., -0.7194,  0.2490, -4.1189],\n",
       "          [-1.1293,  1.0655,  1.3112,  ...,  1.8803, -6.6340, -4.0444]],\n",
       " \n",
       "         [[ 2.5057,  6.8665,  1.0299,  ...,  8.5440, -1.4410, -7.0620],\n",
       "          [ 4.4105,  2.9949, -1.7162,  ...,  4.4722, -0.3008, -2.9338],\n",
       "          [-0.7679, -2.4428, -1.0123,  ..., -1.6110,  2.6296,  0.2919],\n",
       "          ...,\n",
       "          [-1.7249, -1.8000,  4.2837,  ...,  1.0689, -0.8234, -5.0085],\n",
       "          [-0.1915, -0.7245,  2.4475,  ..., -0.7194,  0.2490, -4.1189],\n",
       "          [-1.1293,  1.0655,  1.3112,  ...,  1.8803, -6.6340, -4.0444]]]),\n",
       " 'representations': {6: tensor([[[ 2.5057,  6.8665,  1.0299,  ...,  8.5440, -1.4410, -7.0620],\n",
       "           [ 4.4105,  2.9949, -1.7162,  ...,  4.4722, -0.3008, -2.9338],\n",
       "           [-0.7679, -2.4428, -1.0123,  ..., -1.6110,  2.6296,  0.2919],\n",
       "           ...,\n",
       "           [-1.7249, -1.8000,  4.2837,  ...,  1.0689, -0.8234, -5.0085],\n",
       "           [-0.1915, -0.7245,  2.4475,  ..., -0.7194,  0.2490, -4.1189],\n",
       "           [-1.1293,  1.0655,  1.3112,  ...,  1.8803, -6.6340, -4.0444]],\n",
       "  \n",
       "          [[ 2.5057,  6.8665,  1.0299,  ...,  8.5440, -1.4410, -7.0620],\n",
       "           [ 4.4105,  2.9949, -1.7162,  ...,  4.4722, -0.3008, -2.9338],\n",
       "           [-0.7679, -2.4428, -1.0123,  ..., -1.6110,  2.6296,  0.2919],\n",
       "           ...,\n",
       "           [-1.7249, -1.8000,  4.2837,  ...,  1.0689, -0.8234, -5.0085],\n",
       "           [-0.1915, -0.7245,  2.4475,  ..., -0.7194,  0.2490, -4.1189],\n",
       "           [-1.1293,  1.0655,  1.3112,  ...,  1.8803, -6.6340, -4.0444]]])}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
